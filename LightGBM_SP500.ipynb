{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Ar0P-FoRGh-Z"
   },
   "outputs": [],
   "source": [
    "#!pip install lightgbm\n",
    "#!pip install pandas\n",
    "#!pip install yfinance\n",
    "#!pip install tqdm\n",
    "#!pip install pip install scikit-optimize\n",
    "#!pip install matplotlib\n",
    "#!sudo apt-get install gcc -y\n",
    "#!pip install bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from pandas import Timestamp as ts\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import skopt \n",
    "import skopt.plots\n",
    "from skopt.callbacks import CheckpointSaver\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import bt\n",
    "import os\n",
    "from google.cloud import storage\n",
    "from io import StringIO\n",
    "# CONSTANTS\n",
    "HYPERPARAMETER_OPTIMIZATION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-L-glPNGsBS",
    "outputId": "3285a45c-74f0-40f8-8c13-81964c80b3a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  505 of 505 completed\n",
      "\n",
      "2 Failed downloads:\n",
      "- BRK.B: No data found, symbol may be delisted\n",
      "- BF.B: No data found for this date range, symbol may be delisted\n"
     ]
    }
   ],
   "source": [
    "# Downloadig S&P500 information from wikipedia and Yahoo Finance\n",
    "companyMetadata = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "\n",
    "#if not os.path.isfile('history.csv'):\n",
    "tickers = yf.Tickers(list(companyMetadata['Symbol']))\n",
    "history = tickers.history(period=\"20y\")\n",
    "history.to_csv('history.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QfpXxe3mRQ_H"
   },
   "outputs": [],
   "source": [
    "cleanHistory = history[['Open','Close','High','Low','Volume']] \\\n",
    "        .reorder_levels([1,0],axis=1)\\\n",
    "        .sort_index(axis=1)\\\n",
    "        .dropna(axis= 1, how= 'all')\\\n",
    "        .sort_index()\n",
    "tickers = cleanHistory.columns.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s19dKkvbUxqX",
    "outputId": "150bd189-6d04-4db0-9c1c-5bfd7693c58c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extractFeatures(companyHistory, days):\n",
    "    features = {}#pd.DataFrame()\n",
    "    calculateLabel = lambda series: series/series.shift(1)-1\n",
    "    calculateRatioFeature = lambda series1,series2,days: series1.shift(1+days)/series2.shift(1)\n",
    "\n",
    "    features['label'] = calculateLabel(companyHistory['Open'])\n",
    "    for price in ['Open','Close','High','Low']:\n",
    "        for day in range(days):\n",
    "            features[f'{price}-{day}/Close'] = calculateRatioFeature(companyHistory[price],companyHistory['Close'],day+1)\n",
    "    for day in range(days):\n",
    "        features[f'Volume-{day}/Volume'] = calculateRatioFeature(companyHistory['Volume'],companyHistory['Volume'],day+1)\n",
    "    return pd.DataFrame.from_dict(features).dropna(axis=0,how='any')\n",
    "\n",
    "DAYS = 20\n",
    "\n",
    "features = []\n",
    "for ticker in tqdm(tickers):\n",
    "    features.append(extractFeatures(cleanHistory[ticker],DAYS))\n",
    "features = pd.concat(features,  keys= tickers).reorder_levels([1,0]).sort_index(level=0)\n",
    "train = features.loc[:ts('2018-01-1')]\n",
    "valid = features.loc[ts('2018-01-1'):ts('2020-01-1')]\n",
    "test = features.loc[ts('2020-01-1'):]\n",
    "del features\n",
    "bucket = storage.Client().bucket('sp500-bucket')\n",
    "bucket.blob('train.csv').upload_from_string(train.to_csv(), 'text/csv')\n",
    "bucket.blob('valid.csv').upload_from_string(valid.to_csv(), 'text/csv')\n",
    "bucket.blob('test.csv' ).upload_from_string(test.to_csv() , 'text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading From Google Cloud Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = storage.Client().bucket('sp500-bucket')\n",
    "train = pd.read_csv(StringIO(bucket.blob('train.csv').download_as_string()))\n",
    "valid = pd.read_csv(StringIO(bucket.blob('valid.csv').download_as_string()))\n",
    "test  = pd.read_csv(StringIO(bucket.blob('test.csv' ).download_as_string()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "G0lxg7Kag2pn",
    "outputId": "68a757cc-1a3a-4324-a41d-3674fe7a2b1f"
   },
   "outputs": [],
   "source": [
    "search_space = [\n",
    "skopt.space.Integer(100,500, name = 'num_leaves'),\n",
    "skopt.space.Integer(8, 50, name ='max_depth'),\n",
    "skopt.space.Real(0.001,0.5, name = 'learning_rate'),\n",
    "skopt.space.Real(0.01,1,name = 'colsample_bytree') ,\n",
    "skopt.space.Real(0.01,1, name = 'subsample'),\n",
    "skopt.space.Real(0, 1000, name = 'reg_alpha'),\n",
    "skopt.space.Real(0, 1000, name = 'reg_lambda'), \n",
    "# min_split_gain = skopt.space.Real(name = 'min_split_gain')\n",
    "# min_child_weight = skopt.space.Real(name = 'min_child_weight') \n",
    "# min_child_samples = skopt.space.Integer(name = 'min_child_samples') \n",
    "# subsample_freq = skopt.space.Integer(name = 'subsample_freq') \n",
    "]\n",
    "\n",
    "@skopt.utils.use_named_args(search_space)\n",
    "def objective(**params):\n",
    "    model = lgb.LGBMRegressor(n_estimators = 1000, **params)\n",
    "    eval_result = {}\n",
    "    model.fit(train.drop('label', axis = 1),train['label'], \n",
    "        eval_set = (valid.drop('label', axis = 1),valid['label']),\n",
    "        #verbose=False,\n",
    "        callbacks= [lgb.record_evaluation(eval_result),\n",
    "            lgb.early_stopping(10, verbose=True)])\n",
    "    return min(eval_result['valid_0']['l2'])\n",
    "\n",
    "\n",
    "class ConvergencePlotCallback(object):\n",
    "    def __init__(self, figsize=(12,8)):\n",
    "        self.fig = plt.figure(figsize=figsize)\n",
    "\n",
    "    def __call__(self, res):\n",
    "        clear_output(wait=True)\n",
    "        skopt.plots.plot_convergence(res, yscale=\"log\")\n",
    "        plt.show()\n",
    "plot_callback = ConvergencePlotCallback(figsize=(12,8))\n",
    "checkpoint_callback = CheckpointSaver(\"checkpoint.pkl\")\n",
    "\n",
    "if HYPERPARAMETER_OPTIMIZATION:\n",
    "    results = skopt.gp_minimize(objective,                  # the function to minimize\n",
    "                  search_space,      # the bounds on each dimension of x\n",
    "                  n_calls=1000,         # the number of evaluations of f\n",
    "                  callback=[checkpoint_callback,plot_callback],\n",
    "                  noise=0.1**2)\n",
    "\n",
    "    skopt.plots.plot_convergence(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Taining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Fit Optimal Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.000262269\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's l2: 0.000235695\n",
      "[3]\tvalid_0's l2: 0.000215279\n",
      "[4]\tvalid_0's l2: 0.000199517\n",
      "[5]\tvalid_0's l2: 0.000189404\n",
      "[6]\tvalid_0's l2: 0.00017958\n",
      "[7]\tvalid_0's l2: 0.000171994\n",
      "[8]\tvalid_0's l2: 0.000166203\n",
      "[9]\tvalid_0's l2: 0.000161706\n",
      "[10]\tvalid_0's l2: 0.000158243\n",
      "[11]\tvalid_0's l2: 0.000155625\n",
      "[12]\tvalid_0's l2: 0.000153608\n",
      "[13]\tvalid_0's l2: 0.000152017\n",
      "[14]\tvalid_0's l2: 0.000150789\n",
      "[15]\tvalid_0's l2: 0.000149849\n",
      "[16]\tvalid_0's l2: 0.0001491\n",
      "[17]\tvalid_0's l2: 0.000148556\n",
      "[18]\tvalid_0's l2: 0.000148117\n",
      "[19]\tvalid_0's l2: 0.000147786\n",
      "[20]\tvalid_0's l2: 0.000147553\n",
      "[21]\tvalid_0's l2: 0.000147443\n",
      "[22]\tvalid_0's l2: 0.000147248\n",
      "[23]\tvalid_0's l2: 0.000147149\n",
      "[24]\tvalid_0's l2: 0.000147049\n",
      "[25]\tvalid_0's l2: 0.000146966\n",
      "[26]\tvalid_0's l2: 0.000146907\n",
      "[27]\tvalid_0's l2: 0.000146909\n",
      "[28]\tvalid_0's l2: 0.000146875\n",
      "[29]\tvalid_0's l2: 0.000146844\n",
      "[30]\tvalid_0's l2: 0.000146819\n",
      "[31]\tvalid_0's l2: 0.000146795\n",
      "[32]\tvalid_0's l2: 0.000146786\n",
      "[33]\tvalid_0's l2: 0.00014676\n",
      "[34]\tvalid_0's l2: 0.000146753\n",
      "[35]\tvalid_0's l2: 0.000146757\n",
      "[36]\tvalid_0's l2: 0.000146754\n",
      "[37]\tvalid_0's l2: 0.000146759\n",
      "[38]\tvalid_0's l2: 0.000146753\n",
      "[39]\tvalid_0's l2: 0.000146734\n",
      "[40]\tvalid_0's l2: 0.00014672\n",
      "[41]\tvalid_0's l2: 0.000146721\n",
      "[42]\tvalid_0's l2: 0.000146702\n",
      "[43]\tvalid_0's l2: 0.000146702\n",
      "[44]\tvalid_0's l2: 0.000146705\n",
      "[45]\tvalid_0's l2: 0.0001467\n",
      "[46]\tvalid_0's l2: 0.000146699\n",
      "[47]\tvalid_0's l2: 0.000146713\n",
      "[48]\tvalid_0's l2: 0.00014671\n",
      "[49]\tvalid_0's l2: 0.000146711\n",
      "[50]\tvalid_0's l2: 0.000146692\n",
      "[51]\tvalid_0's l2: 0.000146693\n",
      "[52]\tvalid_0's l2: 0.000146688\n",
      "[53]\tvalid_0's l2: 0.000146681\n",
      "[54]\tvalid_0's l2: 0.000146658\n",
      "[55]\tvalid_0's l2: 0.000146684\n",
      "[56]\tvalid_0's l2: 0.000146682\n",
      "[57]\tvalid_0's l2: 0.000146688\n",
      "[58]\tvalid_0's l2: 0.000146696\n",
      "[59]\tvalid_0's l2: 0.000146704\n",
      "[60]\tvalid_0's l2: 0.000146709\n",
      "[61]\tvalid_0's l2: 0.000146719\n",
      "[62]\tvalid_0's l2: 0.000146733\n",
      "[63]\tvalid_0's l2: 0.000146757\n",
      "[64]\tvalid_0's l2: 0.000146751\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's l2: 0.000146658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(colsample_bytree=0.8711716053585946,\n",
       "              learning_rate=0.12123094384928863, max_depth=14, num_leaves=452,\n",
       "              reg_alpha=6.335223311452995, reg_lambda=640.0933782281086,\n",
       "              subsample=0.4551545343587453)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile('checkpoint.pkl'):\n",
    "    optimalParams = dict(zip ([i.name for i in skopt.load('checkpoint.pkl')['space']],\n",
    "                          skopt.load('checkpoint.pkl')['x']))\n",
    "else:\n",
    "    print(\"Running Base Model\")\n",
    "    optimalParams = {}\n",
    "model = lgb.LGBMRegressor(**optimalParams)\n",
    "eval_result = {}\n",
    "model.fit(train.drop('label', axis = 1),train['label'], \n",
    "    eval_set = (valid.drop('label', axis = 1),valid['label']),\n",
    "    callbacks= [lgb.record_evaluation(eval_result),\n",
    "        lgb.log_evaluation(),\n",
    "        lgb.early_stopping(10, verbose=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pedictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pd.DataFrame(model.predict(test.drop('label', axis = 1)),index = test.index)\n",
    "score.index.rename('Ticker',level=1, inplace = True)\n",
    "score = pd.pivot_table(score, values=0, index='Date', columns='Ticker')\n",
    "close = cleanHistory.reorder_levels([1,0],axis=1)['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopkDropoutStrategy(bt.Algo):\n",
    "    def __init__(self, score, ):\n",
    "        self.score = score\n",
    "        self.holding = None\n",
    "        self.weights = None\n",
    "        \n",
    "    def topkDropoutStrategy(score , holding, k = 100, drop = 1):\n",
    "        if holding is None:\n",
    "            selected = list(score.index[:k]) #Score is already sorted\n",
    "        else:\n",
    "            holdingSorted = score[holding].sort_values(ascending=False)\n",
    "            continueToBeHeld = holdingSorted[:-drop]\n",
    "            rest = score.drop(continueToBeHeld.index)\\\n",
    "                        .sort_values(ascending=False)\n",
    "            bought = rest.index[:drop]\n",
    "            selected = list(continueToBeHeld.index)+list(bought)\n",
    "        return selected\n",
    "    \n",
    "    def __call__(self, target):\n",
    "        if target.now in self.score.index:\n",
    "            score_sorted = self.score.loc[target.now].sort_values(ascending=False)\n",
    "            selected = TopkDropoutStrategy.topkDropoutStrategy(score_sorted,self.holding)\n",
    "                    \n",
    "            target.temp['selected'] = selected\n",
    "            target.temp['holding'] = self.holding\n",
    "            self.holding = selected\n",
    "            # return True because we want to keep on moving down the stack of algs\n",
    "            return True\n",
    "\n",
    "class Weight(bt.Algo):\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "        \n",
    "    def setWeights(holding, selected, past_weights):\n",
    "        weights = {}\n",
    "        numTickers = len(selected)\n",
    "        if past_weights is None:\n",
    "            for ticker in selected:\n",
    "                weights[ticker] = 1/numTickers\n",
    "        else:\n",
    "            weights = {}\n",
    "            bought = set(selected)-set(holding)\n",
    "            sold = set(holding)-set(selected)\n",
    "            \n",
    "            soldCapital = 0\n",
    "            for ticker in sold:\n",
    "                soldCapital += past_weights.pop(ticker)\n",
    "            buyCapitalPerSecurity = soldCapital/len(sold)\n",
    "            \n",
    "            for ticker in selected:\n",
    "                if ticker in holding:\n",
    "                    weights[ticker] = past_weights[ticker]\n",
    "                else:\n",
    "                    weights[ticker] = buyCapitalPerSecurity\n",
    "        return weights\n",
    "\n",
    "    def __call__(self, target):\n",
    "        holding, selected = target.temp['holding'], target.temp['selected']\n",
    "        weights = Weight.setWeights(holding, selected, self.weights)\n",
    "        target.temp['weights'] = weights\n",
    "        self.weights = weights\n",
    "        return True\n",
    "    \n",
    "# first we create the Strategy\n",
    "s = bt.Strategy('topk', [TopkDropoutStrategy(score),\n",
    "                         Weight(),\n",
    "                         bt.algos.Rebalance(),\n",
    "                         bt.algos.RunMonthly(),#bt.algos.RunQuarterly\n",
    "                         bt.algos.WeighEqually(),\n",
    "                         bt.algos.Rebalance(),\n",
    "                         #bt.algos.PrintTempData(),\n",
    "                        ])\n",
    "\n",
    "benchmark = bt.Strategy('benchmark',[bt.algos.SelectAll(),\n",
    "                                    bt.algos.WeighEqually(),\n",
    "                                    bt.algos.Rebalance()])\n",
    "\n",
    "# now we create the Backtest\n",
    "def commissions(q,p):\n",
    "    return abs(q)*p*0.02\n",
    "t = bt.Backtest(s, close.loc[ts('2020-01-1'):], \n",
    "                commissions= commissions,\n",
    "                integer_positions=False,\n",
    "                )\n",
    "b = bt.Backtest(benchmark, bt.get('spy').loc[ts('2020-01-1'):])\n",
    "\n",
    "# and let's run it!\n",
    "res = bt.run(t,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Equity Progression'}>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "res.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LightGBM SP500.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
